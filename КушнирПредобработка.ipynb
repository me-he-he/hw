{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnmPvQDZ5Unx"
      },
      "source": [
        "**Домашнее задание: Предварительная обработка текстовых данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_1_iIzr5s_s"
      },
      "source": [
        "Здесь вам предстоит закрепить навыки нормализации текста, работы с регулярными выражениями, токенизации и удаления стоп-слов. Вы будете работать с первыми двумя главами Мцыри М.Ю. Лермонтова и выполнять различные этапы его предварительной обработки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP3sjSFF5MM-"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "\n",
        "Немного лет тому назад,\n",
        "Там, где, сливаяся, шумят,\n",
        "Обнявшись, будто две сестры,\n",
        "Струи Арагвы и Куры,\n",
        "Был монастырь. Из-за горы\n",
        "И нынче видит пешеход\n",
        "Столбы обрушенных ворот,\n",
        "И башни, и церковный свод;\n",
        "Но не курится уж под ним\n",
        "Кадильниц благовонный дым,\n",
        "Не слышно пенье в поздний час\n",
        "Молящих иноков за нас.\n",
        "Теперь один старик седой,\n",
        "Развалин страж полуживой,\n",
        "Людьми и смертию забыт,\n",
        "Сметает пыль с могильных плит,\n",
        "Которых надпись говорит\n",
        "О славе прошлой — и о том,\n",
        "Как, удручен своим венцом,\n",
        "Такой-то царь, в такой-то год,\n",
        "Вручал России свой народ.\n",
        "И божья благодать сошла\n",
        "На Грузию! Она цвела\n",
        "С тех пор в тени своих садов,\n",
        "Не опасаяся врагов,\n",
        "3а гранью дружеских штыков.\n",
        "\n",
        "Однажды русский генерал\n",
        "Из гор к Тифлису проезжал;\n",
        "Ребенка пленного он вез.\n",
        "Тот занемог, не перенес\n",
        "Трудов далекого пути;\n",
        "Он был, казалось, лет шести,\n",
        "Как серна гор, пуглив и дик\n",
        "И слаб и гибок, как тростник.\n",
        "Но в нем мучительный недуг\n",
        "Развил тогда могучий дух\n",
        "Его отцов. Без жалоб он\n",
        "Томился, даже слабый стон\n",
        "Из детских губ не вылетал,\n",
        "Он знаком пищу отвергал\n",
        "И тихо, гордо умирал.\n",
        "Из жалости один монах\n",
        "Больного призрел, и в стенах\n",
        "Хранительных остался он,\n",
        "Искусством дружеским спасен.\n",
        "Но, чужд ребяческих утех,\n",
        "Сначала бегал он от всех,\n",
        "Бродил безмолвен, одинок,\n",
        "Смотрел, вздыхая, на восток,\n",
        "Гоним неясною тоской\n",
        "По стороне своей родной.\n",
        "Но после к плену он привык,\n",
        "Стал понимать чужой язык,\n",
        "Был окрещен святым отцом\n",
        "И, с шумным светом незнаком,\n",
        "Уже хотел во цвете лет\n",
        "Изречь монашеский обет,\n",
        "Как вдруг однажды он исчез\n",
        "Осенней ночью. Темный лес\n",
        "Тянулся по горам кругом.\n",
        "Три дня все поиски по нем\n",
        "Напрасны были, но потом\n",
        "Его в степи без чувств нашли\n",
        "И вновь в обитель принесли.\n",
        "Он страшно бледен был и худ\n",
        "И слаб, как будто долгий труд,\n",
        "Болезнь иль голод испытал.\n",
        "Он на допрос не отвечал\n",
        "И с каждым днем приметно вял.\n",
        "И близок стал его конец;\n",
        "Тогда пришел к нему чернец\n",
        "С увещеваньем и мольбой;\n",
        "И, гордо выслушав, больной\n",
        "Привстал, собрав остаток сил,\n",
        "И долго так он говорил:\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brfdn2p4759_"
      },
      "source": [
        "Задание 1: Регулярные выражения\n",
        "\n",
        "1.    Напишите регулярное выражение, которое найдет все слова, которые начинаются с сочетания букв \"**ста**\".\n",
        "\n",
        "2.    Напишите регулярное выражение, которое найдет все слова с сочетанием букв **ста** как в начале, так и внутри слов.\n",
        "\n",
        "3. Модернизируйте это выражение так, чтобы буква **т** была опциональной (вместо нее может быть любой другой символ).\n",
        "\n",
        "\n",
        "\n",
        "*Не забывайте импортировать нужные библиотеки*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zsO-zsDNWE8"
      },
      "outputs": [],
      "source": [
        "#задание 1\n",
        "import re\n",
        "search_result = re.findall(r'\\bста\\w*\\b', text)\n",
        "print (search_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8eFM6d5NVqI"
      },
      "outputs": [],
      "source": [
        "#задание 2\n",
        "import re\n",
        "search_result = re.findall(r'ста\\w*\\b', text)\n",
        "print (search_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9kwqv9LNViL"
      },
      "outputs": [],
      "source": [
        "#задание 3\n",
        "import re\n",
        "search_result = re.findall(r'с.{1}а\\w*\\b', text)\n",
        "print (search_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-U8HEuJ6SKY"
      },
      "source": [
        "Задание 2: Нормализация текста\n",
        "\n",
        "1.   Преобразуйте текст из переменной text к нижнему регистру.\n",
        "\n",
        "2.   Удалите все символы пунктуации и переноса строки (\\n), используя регулярные выражения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bf2fygU6y3U"
      },
      "outputs": [],
      "source": [
        "#задание 1\n",
        "lower_text = text.lower()\n",
        "print(lower_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CznWxIMNYnH"
      },
      "outputs": [],
      "source": [
        "#задание 2\n",
        "import re\n",
        "def no_punkt(text):\n",
        "    search_result = re.sub(r'\\.', '', text) \n",
        "    search_result = re.sub(r',', '', search_result) \n",
        "    search_result = re.sub(r'!', '', search_result)  \n",
        "    search_result = re.sub(r':', '', search_result) \n",
        "    search_result = re.sub(r';', '', search_result) \n",
        "    search_result = re.sub(r'\\n', ' ', search_result) \n",
        "    return (search_result)\n",
        "\n",
        "print (no_punkt(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjOxLx7-6z2Z"
      },
      "source": [
        "Задание 3: Токенизация\n",
        "\n",
        "\n",
        "1. Выполните токенизацию нормализованного текста на слова. Сколько токенов в тексте? А сколько уникальных?\n",
        "2. Выполните токенизацию изначального текста на строки при помощи split('\\n'). Отобразите сколько их.\n",
        "3. Напишите цикл, который пройдет по всем токенам текста и сохранит в новой переменной те, которые начинаются с заглавной буквы.\n",
        "4. *Модернизируйте цикл так, чтобы он сохранял в переменную слова с заглавной буквы за исключением тех, которые являются первыми в строке.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS_IGL_aNT3x"
      },
      "outputs": [],
      "source": [
        "#задание 1\n",
        "normal_text = (no_punkt(text.lower()))\n",
        "from nltk import word_tokenize\n",
        "tokens = word_tokenize(normal_text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih1iL6obNTyo"
      },
      "outputs": [],
      "source": [
        "#задание 2\n",
        "def tokenize_lines(text):\n",
        "    lines = text.split('\\n')\n",
        "    return(lines)\n",
        "print (len(tokenize_lines(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCZ5UDpjNTsd"
      },
      "outputs": [],
      "source": [
        "#задание 3\n",
        "import re\n",
        "text = no_punkt(text)\n",
        "from nltk import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "words = []\n",
        "print (tokens)\n",
        "for i in tokens: \n",
        "  if i == (r'[А-Я]\\.*'):\n",
        "    print (i)\n",
        "print (words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#задание 4\n",
        "import re\n",
        "texxt = tokenize_lines(text) \n",
        "for i in range (len(texxt)):\n",
        "       texxt[i] = no_punkt(texxt[i])\n",
        "list = [] \n",
        "for i in (texxt):\n",
        "       word = i.split(' ')\n",
        "       for k in word[1:]:\n",
        "              res = re.fullmatch (r'[А-Я][а-я]+-?[а-я]*', k)\n",
        "              if  res != None:\n",
        "                     list.append (k)\n",
        "print (list)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTuxGyehJnkG"
      },
      "source": [
        "Задание 4: Удаление стоп слов\n",
        "\n",
        "\n",
        "1. Импортируйте список стоп-слов для русского языка из NLTK.\n",
        "2. Напишите цикл, который пройдет по всем токенам и вернет новый список токенов без стоп-слов.\n",
        "3. Сколько слов осталось в тексте? А уникальных?\n",
        "4. *При помощи регулярного выражения найдите все слова с сочетанием букв 'бол' (с опциональной о) внутри слова. Добавьте их к стоп-словам и удалите из текста. Сколько осталось слов в тексте?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmDpig0XNZsT"
      },
      "outputs": [],
      "source": [
        "#задание 1\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk_stopwords_ru = stopwords.words('russian')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shh23e1YNZmV"
      },
      "outputs": [],
      "source": [
        "#задание 2\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk_stopwords_ru = stopwords.words('russian')\n",
        "from nltk import word_tokenize\n",
        "text = no_punkt(text.lower())\n",
        "tokens = word_tokenize(text)\n",
        "def no_stop (tokens):\n",
        "    new_tokens = []\n",
        "    for i in tokens:\n",
        "        if i not in nltk_stopwords_ru:\n",
        "            new_tokens.append (i)\n",
        "    return (new_tokens)\n",
        "print (no_stop (tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jstczD6PNZgj"
      },
      "outputs": [],
      "source": [
        "#задание 3\n",
        "print (len(no_stop (tokens)))\n",
        "print (len(set (no_stop(tokens))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#задание 4\n",
        "text = no_punkt(text.lower())\n",
        "tokens = word_tokenize(text)\n",
        "list = []\n",
        "for i in tokens:\n",
        "    res = re.fullmatch (r'[А-Я]*[а-я]*бо?л[а-я]*', i)\n",
        "    if  res != None:\n",
        "        nltk_stopwords_ru.append (i)\n",
        "print (len(no_stop(tokens)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
